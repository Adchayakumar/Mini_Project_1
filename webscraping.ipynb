{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do with multiple url and save it in separate file\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait  \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time \n",
    "\n",
    "#Movie genre links\n",
    "links=['animation','biography','comedy','crime','documentary','drama','family','fantasy','game-show','history','horror','music','musical','mystery','news','reality-tv','romance','sci-fi','sport','talk-show','thriller','war','western']\n",
    "\n",
    "#Initialize chrome browser\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#Loop for extract the data by genre links\n",
    "for link in links:\n",
    "\n",
    "    #set default empty for all variables\n",
    "    titles = []\n",
    "    ratings = []\n",
    "    votings = []\n",
    "    durations = []\n",
    "\n",
    "    #Navigate to genre-specific IMDb page\n",
    "    url = F'https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres={link}'\n",
    "    driver.get(url)\n",
    "    #Maimize the chrome window size\n",
    "    driver.maximize_window()\n",
    "\n",
    "\n",
    "    #x_path of load more button\n",
    "    load_more_xpath = '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span/button/span/span'\n",
    "    try:\n",
    "        #Create a EC for click a clik load more button\n",
    "        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, load_more_xpath)))\n",
    "        #Find load more button\n",
    "        load_button = driver.find_element(By.XPATH, load_more_xpath)\n",
    "        #Click load more button\n",
    "        ActionChains(driver).move_to_element(load_button).click(load_button).perform()\n",
    "        time.sleep(5)  # Wait for the new content to load\n",
    "        print(\"Clicked 50 more button.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"No more '50 more' button found: {e}\")\n",
    "        \n",
    "    def extract_movie_data():\n",
    "        \"\"\"Extracts movie data from the page using relative paths.\"\"\"\n",
    "        # Get all movie list items\n",
    "        movie_xpath = '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/ul/li'\n",
    "        data_points = driver.find_elements(By.XPATH, movie_xpath)\n",
    "        \n",
    "        print(f\"Found {len(data_points)} movies on the page.\")\n",
    "        \n",
    "        for data in data_points:\n",
    "            try:\n",
    "                # extract each box data into separate variables \n",
    "                title = data.find_element(By.XPATH, './/div/div/div/div[1]/div[2]/div[1]/a/h3').text\n",
    "                rating = data.find_element(By.XPATH, './/div/div/div/div[1]/div[2]/span/div/span/span[1]').text\n",
    "                voting = data.find_element(By.XPATH, './/div/div/div/div[1]/div[2]/span/div/span/span[2]').text\n",
    "                duration = data.find_element(By.XPATH, './/div/div/div/div[1]/div[2]/div[2]/span[2]').text\n",
    "                #store all box data into separate variable\n",
    "                titles.append(title)\n",
    "                ratings.append(rating)\n",
    "                votings.append(voting)\n",
    "                durations.append(duration)\n",
    "\n",
    "                #store it in different csv file genre vise\n",
    "                print(f\"Apended movie is: {title}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting data for one movie: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Once all movies are loaded, extract data one final time to catch any missed items.\n",
    "    extract_movie_data()\n",
    "\n",
    "    print(\"Movie scraping is successfully done\")\n",
    "    print(f\"Total movies scraped: {len(titles)}\")\n",
    "\n",
    "    table={'titles':titles,'durations':durations,'votings':votings,'ratings':ratings}\n",
    "\n",
    "    output=pd.DataFrame(table)\n",
    "    try:\n",
    "        output.to_csv(fr'C:/Users/Admin/Music/New folder/Exception/genere_{link}.csv')\n",
    "        print(f\"We Save the{link} File\")\n",
    "    except Exception as E:\n",
    "        print(\"Saving issue\",E)\n",
    "       \n",
    "driver.quit()    \n",
    "\n",
    "\n",
    "    \n",
    "print('Succesfully finish the scrabing and save the file in desired folder')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# genre names\n",
    "links=['action', 'adventure' ,'animation','biography','comedy','crime','documentary','drama','family','fantasy','game-show','history','horror','music','musical','mystery','news','reality-tv','romance','sci-fi','sport','talk-show','thriller','war','western']\n",
    "merged_df=pd.DataFrame()\n",
    "# using loop clean each csv and store as mergerd csv\n",
    "for link in links:\n",
    "    #Read the CSV file\n",
    "    data=pd.read_csv(Fr\"C:/Users/Admin/Music/New folder/Exception/genere_{link}.csv\")\n",
    "    \n",
    "    df=pd.DataFrame(data)\n",
    "    \n",
    "    #Cleaning the movie name , extract the unwanted letters and synbols and space\n",
    "    df['titles']=df['titles'].str.extract(r'^[^A-Za-z]*(.*)')\n",
    "    df['titles']=df['titles'].str.strip()\n",
    "\n",
    "    df.drop(['Unnamed: 0'],axis=1,inplace=True)  #this drop the index column\n",
    "\n",
    "    #clean hours column and change it to minitues\n",
    "    df['hours']=df['durations'].str.extract(r'(^[0-9])h',expand=False) # store hour value of duartion\n",
    "    df['min']=df['durations'].str.extract(r'(^[0-9])m',expand=False)  # store miniutes value of duration\n",
    "\n",
    "    df['hours']=pd.to_numeric(df['hours'],errors='coerce').fillna(0).astype(int) #Change Data type\n",
    "    df['min']=pd.to_numeric(df['min'],errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    df['duration_min']=(df['hours']*60)+df['min']  # Duration hrs--> miniutes\n",
    "    # drop old duration column\n",
    "    df.drop(['hours','min','durations'],axis=1,inplace=True)\n",
    "\n",
    "    #Clean votings column , remove unwanted string\n",
    "    df['votings'] = df['votings'].astype(str).str.replace(r\"[()\\-\\s]\", \"\", regex=True).str.lower()\n",
    "\n",
    "    # Extract numeric part and convert to float\n",
    "    df['num'] = df['votings'].str.extract(r'([\\d.]+)')[0].astype(float)\n",
    "\n",
    "    # Check if 'k' is present and multiply by 1000 if needed\n",
    "    df['votings'] = (df['num'] * df['votings'].str.contains('k', na=False).replace({True: 1000, False: 1})).fillna(0).astype(int).infer_objects(copy=False)\n",
    "    df.drop(['num'],axis=1,inplace=True)\n",
    "\n",
    "    \n",
    "\n",
    "    df['genere']=link #fill the genre name column\n",
    "    merged_df = pd.concat([merged_df, df], ignore_index=True) # Merge the data\n",
    "    # df.to_csv(r'C:/Users/Admin/Music/Clean_csv/mergedcsv',mode='a', index=False, header=not bool(link == links[0]))\n",
    "\n",
    "#Add MYMDb score column\n",
    "C = merged_df['ratings'].mean()  # Global Mean Rating\n",
    "M = merged_df['votings'].quantile(0.90)  # Minimum Votes Threshold (90th percentile)\n",
    "\n",
    "\n",
    "\n",
    " #  Bayesian Average formule\n",
    "    # score = (V*R)+(M*C)/V+M\n",
    "#  Understanding the Formula  \n",
    "# V (Voting Count): Number of votes received by the movie.\n",
    "# R (Rating): Average rating of the movie.\n",
    "# M (Minimum Votes): A threshold value (e.g., only consider movies with at least 1000 votes).\n",
    "# C (Mean Rating Across All Movies): The global average rating of all movies in the dataset.\n",
    "\n",
    "# Apply Bayesian Average Formula\n",
    "merged_df['score'] = ((merged_df['votings'] * merged_df['ratings']) + (M * C)) / (merged_df['votings'] + M)\n",
    "\n",
    "# Save Final Merged and Cleaned Data\n",
    "merged_df.to_csv(r'C:/Users/Admin/Music/Clean_csv/final_Output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv(r\"C:/Users/Admin/Music/Clean_csv/final_output.csv\")\n",
    "df=pd.DataFrame(data)\n",
    "#add one value for null value\n",
    "value=df.fillna(\"September 5\")\n",
    "print(value.isnull().sum())\n",
    "#save the cleaned file into diffrent file\n",
    "value.to_csv(r\"C:/Users/Admin/Music/Clean_csv/mymdb.csv\",index=False) # this the point final_output change to mymdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv(r\"C:/Users/Admin/Music/Clean_csv/mymdb.csv\")\n",
    "df=pd.DataFrame(data)\n",
    "#round the score column digit\n",
    "df['score']=df['score'].round(2)\n",
    "#Captilize the genre_name\n",
    "df['genere']=df[\"genere\"].str.capitalize()\n",
    "df.to_csv(r\"C:/Users/Admin/Music/Clean_csv/mymdb.csv\",index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create genre mapping dictionary , insert genre_id for genre_name\n",
    "genre_mapping = {\n",
    "    'Action': 1, 'Adventure': 2, 'Animation': 3, 'Biography': 4, 'Comedy': 5,\n",
    "    'Crime': 6, 'Documentary': 7, 'Drama': 8, 'Family': 9, 'Fantasy': 10,\n",
    "    'Game-Show': 11, 'History': 12, 'Horror': 13, 'Music': 14, 'Musical': 15,\n",
    "    'Mystery': 16, 'News': 17, 'Reality-TV': 18, 'Romance': 19, 'Sci-Fi': 20,\n",
    "    'Sport': 21, 'Talk-Show': 22, 'Thriller': 23, 'War': 24, 'Western': 25\n",
    "}\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv('C:/Users/Admin/Music/Clean_csv/mymdb.csv')\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Clean and process 'genere' column\n",
    "df['genere'] = df['genere'].astype(str).str.strip().str.title()  # Standardize text\n",
    "\n",
    "\n",
    "# Map genres to numerical IDs\n",
    "df['genre'] = df['genere'].map(genre_mapping)\n",
    "\n",
    "# Check if any genres are still missing\n",
    "missing_genres = df[df['genre'].isna()]\n",
    "print(\"Missing genres:\", missing_genres['genere'].unique())\n",
    "\n",
    "# Replace NaN values with a default value (e.g., 0 for unknown genres)\n",
    "df['genre'] = df['genre'].fillna(18).astype(int)\n",
    "\n",
    "# Save modified dataframe\n",
    "df.to_csv('C:/Users/Admin/Music/Clean_csv/mymdb2.csv', index=False)\n",
    "\n",
    "# Verify changes\n",
    "print(\"last 5 rows after replacement:\")\n",
    "print(df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(r\"C:/Users/Admin/Music/Clean_csv/mymdb2.csv\")\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "try:\n",
    "    # Connect to the database\n",
    "    connection = pymysql.connect(\n",
    "        host=\"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "        port=4000,\n",
    "        user=\"4V44XYoMA7okY9v.root\",\n",
    "        password=\"IPDxDlc6fXH0d2G0\",\n",
    "        database=\"mymdb\",\n",
    "        ssl_verify_cert=True,\n",
    "        ssl_verify_identity=True,\n",
    "    )\n",
    "    print(\"Connected to server\")\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Ensure column names match the database schema\n",
    "    insert_query = \"\"\"INSERT INTO movie_list (movie_name, ratings, votings, genre_id, score, duration) \n",
    "                      VALUES (%s, %s, %s, %s, %s, %s)\"\"\"\n",
    "\n",
    "    # Convert NaN values to None (NULL in SQL)\n",
    "    df = df[['titles', 'ratings', 'votings', 'genre', 'score', 'duration_min']].where(pd.notna(df), None)\n",
    "\n",
    "    # Convert DataFrame to list of tuples\n",
    "    values = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "    # Execute batch insert\n",
    "    cursor.executemany(insert_query, values)\n",
    "    connection.commit()\n",
    "    print(\"Values added successfully\")\n",
    "\n",
    "except pymysql.MySQLError as error:\n",
    "    print(\"Error:\", error)\n",
    "\n",
    "finally: #Close the connection\n",
    "    if 'connection' in locals() and connection.open:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"Connection closed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mymdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
